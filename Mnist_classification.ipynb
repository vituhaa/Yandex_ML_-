{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vituhaa/Yandex_ML_-/blob/main/Mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYUNn8UMYI5e"
      },
      "source": [
        "## Классификация MNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIYDmK7TYI5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dmXMM-EYI5g"
      },
      "source": [
        "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
        "\n",
        "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdCYvvLvYI5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "df564f72-5d92-4af4-fd56-de35ce45ea7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 6')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_mnist_data,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f'Image label: {_label}')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dCCrLG7YI5h"
      },
      "source": [
        "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
        "\n",
        "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
        "\n",
        "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdgk1AvVYI5h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# класс для построения нейросети.\n",
        "# Чтобы создать нейронную сеть в PyTorch, используется класс nn.Module.\n",
        "# Чтобы им воспользоваться, необходимо наследование, что позволит использовать весь функционал базового класса nn.Module,\n",
        "# но при этом еще имеется возможность переписать базовый класс для конструирования модели или прямого прохождения через сеть.\n",
        "class mlp(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() # функция создает объект базового класса\n",
        "    # создаем полностью соединенные слои\n",
        "    # Полностью соединенный слой нейронной сети представлен объектом nn.Linear, в котором первый аргумент — определение количества узлов в i-том слое, а второй — количество узлов в i+1 слое.\n",
        "    self.fc1 = nn.Linear(28*28, 200)\n",
        "    self.fc2 = nn.Linear(200, 200)\n",
        "    self.fc3 = nn.Linear(200, 10)\n",
        "\n",
        "\n",
        "  # После определения скелета архитектуры сети, необходимо задать принципы, по которым данные будут перемещаться по ней.\n",
        "  # Это делается с помощью определяемого метода forward(),  который переписывает фиктивный метод в базовом классе и требует определения для каждой сети\n",
        "  # Для метода forward() берем входные данные x в качестве основного аргумента.\n",
        "  # Далее, загружаем всё в в первый полностью соединенный слой self.fc1(x) и применяем активационную функцию ReLU для узлов в этом слое, используя F.relu().\n",
        "  # Из-за иерархической природы этой нейронной сети, заменяем x на каждой стадии и отправляем на следующий слой. Делаем эту процедуру на трех соединенных слоях, за исключением последнего.\n",
        "  # На последнем слое возвращаем не ReLU, а логарифмическую softmax активационную функцию. Это, в комбинации с функцией потери отрицательного логарифмического правдоподобия, дает\n",
        "  # многоклассовую на основе кросс-энтропии функцию потерь, которую мы будет использовать для тренировки сети.\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = mlp() # создание экземпляра (instance) этой архитектуры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyoxFSWIYI5h"
      },
      "source": [
        "Ниже доступны локальные тесты для проверки вашей модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY8VLWuHYI5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5514ba-fdc0-4d4f-e450-e5250e128dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, 'Please, use `model` variable to store your model'\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].reshape(-1, 784)\n",
        "    y = random_batch[1]\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print('Something is wrong with the model')\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
        "\n",
        "print('Everything seems fine!')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjiisXwwYI5i"
      },
      "source": [
        "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtlNvGkwYI5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e150ea1-a0a2-4c06-85d2-86a345ff5d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 [0/60000] Loss: 2.284314\n",
            "Epoch 1 [3200/60000] Loss: 0.962919\n",
            "Epoch 1 [6400/60000] Loss: 0.331532\n",
            "Epoch 1 [9600/60000] Loss: 0.768535\n",
            "Epoch 1 [12800/60000] Loss: 0.343119\n",
            "Epoch 1 [16000/60000] Loss: 0.402709\n",
            "Epoch 1 [19200/60000] Loss: 0.257761\n",
            "Epoch 1 [22400/60000] Loss: 0.264786\n",
            "Epoch 1 [25600/60000] Loss: 0.390902\n",
            "Epoch 1 [28800/60000] Loss: 0.085976\n",
            "Epoch 1 [32000/60000] Loss: 0.108729\n",
            "Epoch 1 [35200/60000] Loss: 0.318544\n",
            "Epoch 1 [38400/60000] Loss: 0.163669\n",
            "Epoch 1 [41600/60000] Loss: 0.180163\n",
            "Epoch 1 [44800/60000] Loss: 0.129583\n",
            "Epoch 1 [48000/60000] Loss: 0.252280\n",
            "Epoch 1 [51200/60000] Loss: 0.048322\n",
            "Epoch 1 [54400/60000] Loss: 0.103879\n",
            "Epoch 1 [57600/60000] Loss: 0.176202\n",
            "Epoch 2 [0/60000] Loss: 0.061822\n",
            "Epoch 2 [3200/60000] Loss: 0.141693\n",
            "Epoch 2 [6400/60000] Loss: 0.129454\n",
            "Epoch 2 [9600/60000] Loss: 0.100751\n",
            "Epoch 2 [12800/60000] Loss: 0.066967\n",
            "Epoch 2 [16000/60000] Loss: 0.054937\n",
            "Epoch 2 [19200/60000] Loss: 0.055844\n",
            "Epoch 2 [22400/60000] Loss: 0.305614\n",
            "Epoch 2 [25600/60000] Loss: 0.028594\n",
            "Epoch 2 [28800/60000] Loss: 0.439342\n",
            "Epoch 2 [32000/60000] Loss: 0.013257\n",
            "Epoch 2 [35200/60000] Loss: 0.038985\n",
            "Epoch 2 [38400/60000] Loss: 0.115861\n",
            "Epoch 2 [41600/60000] Loss: 0.018169\n",
            "Epoch 2 [44800/60000] Loss: 0.051484\n",
            "Epoch 2 [48000/60000] Loss: 0.127377\n",
            "Epoch 2 [51200/60000] Loss: 0.222718\n",
            "Epoch 2 [54400/60000] Loss: 0.114238\n",
            "Epoch 2 [57600/60000] Loss: 0.146912\n",
            "Epoch 3 [0/60000] Loss: 0.044010\n",
            "Epoch 3 [3200/60000] Loss: 0.133735\n",
            "Epoch 3 [6400/60000] Loss: 0.186283\n",
            "Epoch 3 [9600/60000] Loss: 0.200157\n",
            "Epoch 3 [12800/60000] Loss: 0.027719\n",
            "Epoch 3 [16000/60000] Loss: 0.028253\n",
            "Epoch 3 [19200/60000] Loss: 0.134286\n",
            "Epoch 3 [22400/60000] Loss: 0.277034\n",
            "Epoch 3 [25600/60000] Loss: 0.092386\n",
            "Epoch 3 [28800/60000] Loss: 0.056350\n",
            "Epoch 3 [32000/60000] Loss: 0.048043\n",
            "Epoch 3 [35200/60000] Loss: 0.177569\n",
            "Epoch 3 [38400/60000] Loss: 0.016596\n",
            "Epoch 3 [41600/60000] Loss: 0.049049\n",
            "Epoch 3 [44800/60000] Loss: 0.076694\n",
            "Epoch 3 [48000/60000] Loss: 0.105528\n",
            "Epoch 3 [51200/60000] Loss: 0.019283\n",
            "Epoch 3 [54400/60000] Loss: 0.003442\n",
            "Epoch 3 [57600/60000] Loss: 0.033861\n",
            "Epoch 4 [0/60000] Loss: 0.102779\n",
            "Epoch 4 [3200/60000] Loss: 0.016727\n",
            "Epoch 4 [6400/60000] Loss: 0.010096\n",
            "Epoch 4 [9600/60000] Loss: 0.135884\n",
            "Epoch 4 [12800/60000] Loss: 0.064035\n",
            "Epoch 4 [16000/60000] Loss: 0.148107\n",
            "Epoch 4 [19200/60000] Loss: 0.018282\n",
            "Epoch 4 [22400/60000] Loss: 0.070374\n",
            "Epoch 4 [25600/60000] Loss: 0.041882\n",
            "Epoch 4 [28800/60000] Loss: 0.041175\n",
            "Epoch 4 [32000/60000] Loss: 0.069752\n",
            "Epoch 4 [35200/60000] Loss: 0.052382\n",
            "Epoch 4 [38400/60000] Loss: 0.062244\n",
            "Epoch 4 [41600/60000] Loss: 0.010449\n",
            "Epoch 4 [44800/60000] Loss: 0.039064\n",
            "Epoch 4 [48000/60000] Loss: 0.066192\n",
            "Epoch 4 [51200/60000] Loss: 0.064743\n",
            "Epoch 4 [54400/60000] Loss: 0.269440\n",
            "Epoch 4 [57600/60000] Loss: 0.039368\n",
            "Epoch 5 [0/60000] Loss: 0.007933\n",
            "Epoch 5 [3200/60000] Loss: 0.040573\n",
            "Epoch 5 [6400/60000] Loss: 0.017687\n",
            "Epoch 5 [9600/60000] Loss: 0.007724\n",
            "Epoch 5 [12800/60000] Loss: 0.003939\n",
            "Epoch 5 [16000/60000] Loss: 0.008290\n",
            "Epoch 5 [19200/60000] Loss: 0.176690\n",
            "Epoch 5 [22400/60000] Loss: 0.020803\n",
            "Epoch 5 [25600/60000] Loss: 0.113764\n",
            "Epoch 5 [28800/60000] Loss: 0.009358\n",
            "Epoch 5 [32000/60000] Loss: 0.161636\n",
            "Epoch 5 [35200/60000] Loss: 0.082336\n",
            "Epoch 5 [38400/60000] Loss: 0.102451\n",
            "Epoch 5 [41600/60000] Loss: 0.124374\n",
            "Epoch 5 [44800/60000] Loss: 0.041624\n",
            "Epoch 5 [48000/60000] Loss: 0.041731\n",
            "Epoch 5 [51200/60000] Loss: 0.093865\n",
            "Epoch 5 [54400/60000] Loss: 0.012231\n",
            "Epoch 5 [57600/60000] Loss: 0.048657\n",
            "Epoch 6 [0/60000] Loss: 0.025792\n",
            "Epoch 6 [3200/60000] Loss: 0.011316\n",
            "Epoch 6 [6400/60000] Loss: 0.010207\n",
            "Epoch 6 [9600/60000] Loss: 0.005767\n",
            "Epoch 6 [12800/60000] Loss: 0.022778\n",
            "Epoch 6 [16000/60000] Loss: 0.040484\n",
            "Epoch 6 [19200/60000] Loss: 0.007027\n",
            "Epoch 6 [22400/60000] Loss: 0.040135\n",
            "Epoch 6 [25600/60000] Loss: 0.174767\n",
            "Epoch 6 [28800/60000] Loss: 0.016775\n",
            "Epoch 6 [32000/60000] Loss: 0.056899\n",
            "Epoch 6 [35200/60000] Loss: 0.007523\n",
            "Epoch 6 [38400/60000] Loss: 0.030504\n",
            "Epoch 6 [41600/60000] Loss: 0.014064\n",
            "Epoch 6 [44800/60000] Loss: 0.011307\n",
            "Epoch 6 [48000/60000] Loss: 0.012207\n",
            "Epoch 6 [51200/60000] Loss: 0.037897\n",
            "Epoch 6 [54400/60000] Loss: 0.059650\n",
            "Epoch 6 [57600/60000] Loss: 0.155100\n",
            "Epoch 7 [0/60000] Loss: 0.008493\n",
            "Epoch 7 [3200/60000] Loss: 0.054903\n",
            "Epoch 7 [6400/60000] Loss: 0.049803\n",
            "Epoch 7 [9600/60000] Loss: 0.007400\n",
            "Epoch 7 [12800/60000] Loss: 0.002177\n",
            "Epoch 7 [16000/60000] Loss: 0.016937\n",
            "Epoch 7 [19200/60000] Loss: 0.019242\n",
            "Epoch 7 [22400/60000] Loss: 0.017326\n",
            "Epoch 7 [25600/60000] Loss: 0.019659\n",
            "Epoch 7 [28800/60000] Loss: 0.005875\n",
            "Epoch 7 [32000/60000] Loss: 0.057021\n",
            "Epoch 7 [35200/60000] Loss: 0.050245\n",
            "Epoch 7 [38400/60000] Loss: 0.018467\n",
            "Epoch 7 [41600/60000] Loss: 0.004022\n",
            "Epoch 7 [44800/60000] Loss: 0.000765\n",
            "Epoch 7 [48000/60000] Loss: 0.024434\n",
            "Epoch 7 [51200/60000] Loss: 0.016456\n",
            "Epoch 7 [54400/60000] Loss: 0.003605\n",
            "Epoch 7 [57600/60000] Loss: 0.008678\n",
            "Epoch 8 [0/60000] Loss: 0.030039\n",
            "Epoch 8 [3200/60000] Loss: 0.029240\n",
            "Epoch 8 [6400/60000] Loss: 0.003046\n",
            "Epoch 8 [9600/60000] Loss: 0.008520\n",
            "Epoch 8 [12800/60000] Loss: 0.015481\n",
            "Epoch 8 [16000/60000] Loss: 0.002405\n",
            "Epoch 8 [19200/60000] Loss: 0.001012\n",
            "Epoch 8 [22400/60000] Loss: 0.053394\n",
            "Epoch 8 [25600/60000] Loss: 0.002533\n",
            "Epoch 8 [28800/60000] Loss: 0.050798\n",
            "Epoch 8 [32000/60000] Loss: 0.008280\n",
            "Epoch 8 [35200/60000] Loss: 0.086066\n",
            "Epoch 8 [38400/60000] Loss: 0.000273\n",
            "Epoch 8 [41600/60000] Loss: 0.047742\n",
            "Epoch 8 [44800/60000] Loss: 0.005285\n",
            "Epoch 8 [48000/60000] Loss: 0.017892\n",
            "Epoch 8 [51200/60000] Loss: 0.012584\n",
            "Epoch 8 [54400/60000] Loss: 0.076723\n",
            "Epoch 8 [57600/60000] Loss: 0.011709\n",
            "Epoch 9 [0/60000] Loss: 0.011141\n",
            "Epoch 9 [3200/60000] Loss: 0.038890\n",
            "Epoch 9 [6400/60000] Loss: 0.001973\n",
            "Epoch 9 [9600/60000] Loss: 0.138222\n",
            "Epoch 9 [12800/60000] Loss: 0.017189\n",
            "Epoch 9 [16000/60000] Loss: 0.086458\n",
            "Epoch 9 [19200/60000] Loss: 0.006761\n",
            "Epoch 9 [22400/60000] Loss: 0.041594\n",
            "Epoch 9 [25600/60000] Loss: 0.006266\n",
            "Epoch 9 [28800/60000] Loss: 0.010210\n",
            "Epoch 9 [32000/60000] Loss: 0.005058\n",
            "Epoch 9 [35200/60000] Loss: 0.034906\n",
            "Epoch 9 [38400/60000] Loss: 0.023683\n",
            "Epoch 9 [41600/60000] Loss: 0.003266\n",
            "Epoch 9 [44800/60000] Loss: 0.035225\n",
            "Epoch 9 [48000/60000] Loss: 0.038181\n",
            "Epoch 9 [51200/60000] Loss: 0.006478\n",
            "Epoch 9 [54400/60000] Loss: 0.003291\n",
            "Epoch 9 [57600/60000] Loss: 0.012070\n",
            "Epoch 10 [0/60000] Loss: 0.022588\n",
            "Epoch 10 [3200/60000] Loss: 0.013280\n",
            "Epoch 10 [6400/60000] Loss: 0.029662\n",
            "Epoch 10 [9600/60000] Loss: 0.013637\n",
            "Epoch 10 [12800/60000] Loss: 0.001732\n",
            "Epoch 10 [16000/60000] Loss: 0.002845\n",
            "Epoch 10 [19200/60000] Loss: 0.004366\n",
            "Epoch 10 [22400/60000] Loss: 0.000763\n",
            "Epoch 10 [25600/60000] Loss: 0.006094\n",
            "Epoch 10 [28800/60000] Loss: 0.090944\n",
            "Epoch 10 [32000/60000] Loss: 0.007876\n",
            "Epoch 10 [35200/60000] Loss: 0.004993\n",
            "Epoch 10 [38400/60000] Loss: 0.022735\n",
            "Epoch 10 [41600/60000] Loss: 0.059885\n",
            "Epoch 10 [44800/60000] Loss: 0.002573\n",
            "Epoch 10 [48000/60000] Loss: 0.220899\n",
            "Epoch 10 [51200/60000] Loss: 0.000317\n",
            "Epoch 10 [54400/60000] Loss: 0.038031\n",
            "Epoch 10 [57600/60000] Loss: 0.000247\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "\n",
        "# Далее необходимо задать метод оптимизации и критерий качества:\n",
        "# # Осуществляем оптимизацию путем стохастического градиентного спуска\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "# создаём функцию потерь\n",
        "criterion = nn.NLLLoss()\n",
        "log_interval = 100\n",
        "\n",
        "# запускаем главный тренировочный цикл\n",
        "for epoch in range(epochs):\n",
        "   for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "       data, target = data, target\n",
        "\n",
        "# изменим размер с (batch_size, 1, 28, 28) на (batch_size, 28*28)\n",
        "       data = data.view(-1, 28*28)\n",
        "       optimizer.zero_grad()\n",
        "       net_out = model(data)\n",
        "       loss = criterion(net_out, target)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       if batch_idx % log_interval == 0:\n",
        "           print(f\"Epoch {epoch+1} [{batch_idx*len(data)}/{len(train_data_loader.dataset)}] \"\n",
        "      f\"Loss: {loss.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyieNOBnYI5i"
      },
      "source": [
        "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98PDITfOYI5i"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRGf4SZRYI5i"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSifQ4dvYI5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0118581a-7580-451d-d6ed-a21666a6c949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.99775\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fv7G2_vYI5j"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].reshape(-1, 784))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd19cm_dYI5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef27cc8-172d-44d1-8852-6f5086479839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9813\n"
          ]
        }
      ],
      "source": [
        "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyGIDC2dYI5j"
      },
      "source": [
        "Проверка, что пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_Nj1qQ1YI5j"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
        "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRaRzcgtYI5j"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiIZYqaVYI5j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ---- подготовка модели/окружения ----\n",
        "# ВАЖНО: модель должна быть уже объявлена/загружена к этому моменту.\n",
        "# Перенесём её на CPU и в eval-режим.\n",
        "model = model.cpu()\n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# ---- проверка данных ----\n",
        "assert os.path.exists('hw_mnist_data_dict.npy'), \\\n",
        "    'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
        "\n",
        "# np.load может вернуть 0-мерный объект с dict или сразу dict\n",
        "loaded_raw = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
        "loaded_data_dict = loaded_raw.item() if not isinstance(loaded_raw, dict) else loaded_raw\n",
        "\n",
        "def get_predictions(model: torch.nn.Module, eval_data_np: np.ndarray, step: int = 128) -> str:\n",
        "    \"\"\"\n",
        "    Возвращает строку меток через запятую: '1,4,0,...'\n",
        "    \"\"\"\n",
        "    # Преобразуем в тензор float32 на CPU\n",
        "    eval_data = torch.as_tensor(eval_data_np, dtype=torch.float32, device='cpu')\n",
        "    preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # прогон батчами\n",
        "        n = len(eval_data)\n",
        "        for i in range(0, n, step):\n",
        "            batch = eval_data[i:i+step].reshape(-1, 784)  # [B, 784]\n",
        "            logits = model(batch)                        # [B, C]\n",
        "            y_hat = logits.argmax(dim=1)                 # [B]\n",
        "            preds.append(y_hat.cpu())\n",
        "\n",
        "    labels = torch.cat(preds, dim=0).tolist()           # list[int]\n",
        "    return ','.join(str(x) for x in labels)\n",
        "\n",
        "submission_dict = {\n",
        "    'train': get_predictions(model, loaded_data_dict['train']),\n",
        "    'test':  get_predictions(model, loaded_data_dict['test']),\n",
        "}\n",
        "\n",
        "# ВАЖНО: имя файла — именно submission_dict.json\n",
        "with open('submission_dict.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(submission_dict, f, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMwwv2agYI5j"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw3V-Mf4YI5k"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "facelv_1.13+cu117",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}